{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "907c2b87-59df-43b1-8739-2a67fe2aa103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jarod\\anaconda3\\envs\\PatRecEnv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jarod\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "#import spacy\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import sklearn\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4f94dbf-4dd5-4614-9faf-e1de3482a972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['source', 'id', 'text'],\n",
       "        num_rows: 1392522\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('artem9k/ai-text-detection-pile')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c66421c-7c75-4e47-9fbf-fcb80ee7ef1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>12 Years a Slave: An Analysis of the Film Essa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>human</td>\n",
       "      <td>1</td>\n",
       "      <td>20+ Social Media Post Ideas to Radically Simpl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>human</td>\n",
       "      <td>2</td>\n",
       "      <td>2022 Russian Invasion of Ukraine in Global Med...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>human</td>\n",
       "      <td>3</td>\n",
       "      <td>533 U.S. 27 (2001) Kyllo v. United States: The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>human</td>\n",
       "      <td>4</td>\n",
       "      <td>A Charles Schwab Corporation Case Essay\\n\\nCha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source  id                                               text\n",
       "0  human   0  12 Years a Slave: An Analysis of the Film Essa...\n",
       "1  human   1  20+ Social Media Post Ideas to Radically Simpl...\n",
       "2  human   2  2022 Russian Invasion of Ukraine in Global Med...\n",
       "3  human   3  533 U.S. 27 (2001) Kyllo v. United States: The...\n",
       "4  human   4  A Charles Schwab Corporation Case Essay\\n\\nCha..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(dataset['train'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6323cca1-d0ae-4360-a9d8-b9b98da386ba",
   "metadata": {},
   "source": [
    "## Reformat Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "289dd23b-4e5a-44bf-8029-9069bc8ede0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['human', 'ai'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['source'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f39557c-98f8-4b87-8953-2feb001c23c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['source'] = [1 if x == 'ai' else 0 for x in df['source']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "574b8722-eba1-4a8c-b0ea-38220c9e832d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12 Years a Slave: An Analysis of the Film Essa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20+ Social Media Post Ideas to Radically Simpl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2022 Russian Invasion of Ukraine in Global Med...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>533 U.S. 27 (2001) Kyllo v. United States: The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>A Charles Schwab Corporation Case Essay\\n\\nCha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source  id                                               text\n",
       "0       0   0  12 Years a Slave: An Analysis of the Film Essa...\n",
       "1       0   1  20+ Social Media Post Ideas to Radically Simpl...\n",
       "2       0   2  2022 Russian Invasion of Ukraine in Global Med...\n",
       "3       0   3  533 U.S. 27 (2001) Kyllo v. United States: The...\n",
       "4       0   4  A Charles Schwab Corporation Case Essay\\n\\nCha..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d38a2a6-f87d-4e10-9f7e-a7ae4c76e2fa",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7602dbfe-77ef-491e-acf4-89dc348f34fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "0    1028146\n",
       "1     364376\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['source']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d4b0ec-1051-45fb-a060-2b0952d51f52",
   "metadata": {},
   "source": [
    "We have unequal samples for each class. We will most likely have to resample based on the methods we intend to do that may require equal class sizes. We can figure that out later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4413eb-f39e-4334-9af6-0b5b6a0b0459",
   "metadata": {},
   "source": [
    "#### TBD: Work on more data exploration focusing on the content of the text if time permits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "683ae0d6-866f-4af8-8959-fcecae6722b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<LongWritable,Text,Text,IntWritable>', '<Text,IntWritable,Text,IntWritable>']\n",
      "['<…>', '<…>']\n",
      "['<10 w, 10-1kw, >', '<80°C, 80°- 500°C, >']\n",
      "['< anArray [mid]). Base cases for binary search could be both first >']\n",
      "['<95th) percentiles (“Georgia,” n.d.). Consequently, Georgia is ranked 14 out of 50 states with high obesity (“Georgia,” n.d.). Moreover, approximately 77% of children in Georgia have High BMI rates (Helland & Nordbotten, 2021). Nutrition assistance programs are considered healthy as they minimize the risk of increased body weight, overweight, or obesity. Reducing calorie-dense foods among African American and Hispanic communities will minimize excessive caloric intake.\\n\\nHealth Disparities and Inequalities in Georgia\\n\\nDisparities in access to healthy foods follow ethnic, racial, socio-economic status, and geographic location. The inexpensive nature of calorie-rich foods contributes to poor eating habits in urban areas. For example, in 2019, Georgian children living below federal poverty levels remained at 19.5%, translating to 479,379 minors (“Children living in poverty in Georgia,” n.d). The most affected groups are native Hawaiians at 39.8%, Alaskan natives at 28.5%, non-Hispanic Americans at 22.9%, and Hispanics at 20% (Willis, 2020). Boys have a higher risk of becoming obese compared to girls in Georgia.\\n\\nPrimary Community Resources and Primary Prevention Resources\\n\\nGeorgia incorporates state, regional, and local resources in minimizing school-based obesity. Georgia SHAPE initiative seeks to achieve healthy weight among 69% of children by 2023 (“About Georgia shape,” n.d). In 1996, the Atlanta physical activity and nutrition (PAN) instituted a Go Girls health behavior intervention program. ‘Go Girls’ is a program that targets African American adolescent girls in improving their diets and physical activity. In 1996, the Georgia Coalition for nutrition education (GCNE) implemented state-level policies to address childhood nutrition and physical exercise (Satcher, 2017). In 999, Kids Health or ‘HealthMPowers’ was established by a non-profit organization to enhance school-based healthy eating and physical activity.\\n\\nUnderlying Causes of the Health Concern\\n\\nChildhood obesity comes from multiple factors such as genetics, environment, and socio-economic status. Genetic factors define metabolism attributes that result in excess weight gain. Environmental factors contributing to high obesity include fast foods, minimal physical activity, and sedentary lifestyles (Diao et al., 2020). The school environment incorporates vending machines that dispense snack bars, sodas, or fried vegetables (Blomme et. 2020). Low-income neighborhoods have limited access to large grocery stores that sell fresh fruits and vegetables. Disparities in access indicate more than a 1-mile distance to the nearest store.\\n\\nEvidence-Based Practice\\n\\nHealth education interventions in school settings improve the public health potential of lowering BMI among teenagers. The government utilizes health education in schools as part of the childhood obesity strategy (Jacob et al., 2021). Schools will be the targets of the nutrition education campaign. Schools admit many teenagers and adolescents offer opportunities to practice healthy eating patterns to high-risk populations. Teenagers from low-income communities access one to three main meals from the school cafeteria.\\n\\nData at State and County Levels\\n\\nGeorgia struggles to meet the global nutrition targets to minimize rising cases of overweight children. Youth risk behavior surveillance systems reported that 14.8% of high school teenagers were obese in the United States, while 15.6% were considered overweight (Pirani, 2018). Georgia is ranked 18th out of 51 in teenage obesity among 10-17-year-olds (Pirani, 2018). Poorer rankings are reported among children from 2-4 years at 36 out of 51 (Pirani, 2018). Moreover, Paulding county’s ranking has a health outcome of 9 and a health factor of 18 (Blomme et al., 2020). Poor health outcomes cover factors such as length of life and quality of life.\\n\\nCommunity Health Nursing Social Media Campaign Strategy\\n\\nSocial Media Campaign Objective\\n\\nThe objective of the nutrition education promotion campaign will encourage students to adopt healthy eating habits. Nurses based in primary healthcare facilities are mandated with health promotion activities to prevent and control obesity (Braga et al., 2020). The healthy snack campaign will promote science-based nutritional standards for snacks and beverages provided in schools. The Healthy snack guidelines will increase food items such as vegetables, dairy products, fruits, proteins, and whole-grain products.\\n\\nPopulation-Focused Social Marketing Interventions\\n\\nSocial marketing seeks to promote changes in behavior or communicate information to a target audience. Population-focused social marketing interventions will include nutrition communication targeting parents and food marketing targeting schools in Georgia (Akbar et al., 2021). Parents will benefit from healthy eating seminars, home nutrition charts, and nutrient analysis checklists. However, schools will be required to limit the marketing of processed foods, fast foods, and soft drinks in the school compound. School-based marketing for brands will be replaced with healthy food items such as fruits or low-fat dairy products (Akbar et al., 2021). Schools will offer students free water in cafeterias, play yards, school days, and after-school activities.\\n\\nThe Social Media Platform\\n\\nFacebook will be appropriate for reaching parents of at-risk teenagers. Facebook is a public social media platform that is accessible to anyone. Healthcare providers prefer the platform for providing users with information in video, links, images, and long text formats (Abo-Alhija, 2021). Organizations promote products on Facebook pages, personal profiles, or groups. Users must have personal profiles to log in and monitor user metrics such as comments, shares, notifications, or likes. Facebook pages offer demographic data for analyzing content reach and page interactions.\\n\\nBenefits of Social Media Platforms\\n\\nFacebook is an easy platform to use to enhance information dissemination to parents concerning enrollment and attendance of in-person intervention programs. Facebook users prefer engaging video content and nutritional information during cooking demonstrations, cultural recipes, or events. Popularity and high internet penetration mean over 47% of adults and 72% of youth can access Facebook (Swindle et al., 2018). Consequently, personal stories generate more impact on stakeholders through high engagement with the platform.\\n\\nThe Benefit of Health Message\\n\\nThe coordinated school health (CSH) program will promote health education, school health services, and nutritional information. Guidance to healthy eating habits will come from nutritionists, endocrinologists, or anthropometric evaluations (Braga et al., 2020). The goal is to improve students’ knowledge of the various food groups, healthy food preparation methods, and malnutrition symptoms among patients. School lunches offer opportunities for teenagers to practice healthy eating habits as a daily routine. Moreover, policymakers will prioritize teenagers from low-income communities in accessing a healthy combination of meals from the school cafeteria.\\n\\nBest Practices\\n\\nEngaging posts must include various content such as videos, quizzes, widgets, and images. Best practices involve hiring social media strategists to identify campaign objectives to identify pictures. Campaign strategists must visit Facebook sites posting similar content to assess user engagement rates, cultures, commenting policies, and functionality (Elsayed et al., 2021). The communication strategy must meet healthcare objectives such as BMI reduction or diabetes screening programs. Employees must have adequate financial and human resources to keep the campaign going.\\n\\nStakeholder Roles and Responsibilities\\n\\nStakeholders involved in the project will include members of school committees. School committees will include parents, district food service managers, and healthcare professionals. School personnel will include the school nurse, district administrators, physical education instructors, and staff members (Vall et al., 2017). School personnel will ensure the implementation of health and nutritional education curriculums. The principal will ensure school personnel adheres to new regulations surrounding the nutritional components of school lunches.\\n\\nPotential Public and Private Partnerships\\n\\nThe ten-year Georgia SHAPE statewide program integrates over 125 philanthropic, private sector, and government entities. The governor’s advisory council on childhood obesity will incorporate district-level recommendations from government offices, charitable organizations, and the private sector. Government institutions will include the department of public health, education, and the medical community (Vall et al., 2017). Evidence-based nutritional information will come from academic experts such as universities or research facilities.\\n\\nTimeline\\n\\nThe social media campaign will cover six months to achieve short-term and long-term goals. The first month will incorporate the campaign planning phase will identify the population health problem that needs urgent attention. The second month will require mapping key stakeholder needs such as parents, the private sector, and the ministry of health. The third month will incorporate advocacy duties, and in the fourth month, campaign managers will include key stakeholders.\\n\\nCampaign Effectiveness\\n\\nEducators in Georgia will collect physical measurements of the BMI of all children enrolled in public schools. The FitnessGram is a fitness assessment tool that incorporates scientific standards for schools to evaluate fitness levels among students. Schools will collect BMI measurements by classifying high-risk students within and outside the healthy fitness zone. Students in the BMI 85th <95th or BMI>']\n",
      "['<“Human Rights, Terrorism and Counter-terrorism” Fact Sheet No. 32>']\n",
      "['<…>']\n",
      "['<…>']\n",
      "['<…>']\n",
      "['< 0.05). In contrast, age, air conditioning, and pool are not statistically significant predictors (p >']\n",
      "['<100kB                                                                                                                                                                                                                                                                                                                                              \\nSize of the photo        >', '<1mB                           The size of the photo will determine such parameter into three categories, i.e. small, medium and large pictures.                                                                                                                                 The Exif metadata of the picture                       \\n                         >', '<facet id=”brand”>', '</facet>', '<facet id=”model”>', '</facet>', '<facet id=”country_manufacturer”>', '</facet>', '<facet id=”body_style”>', '</facet>', '<facet id=”year_manufacture”>', '</facet>', '<facet id=”brand”>', '</facet>', '<topic id=” Alfa Romeo” facet_id=”brand”>', '<name>', '</name>', '</topic>']\n",
      "['<–>', '<–>', '<–>', '<–>']\n",
      "['< 0.001). The post-test results averaged at 65.3% ± 7.7%. 11 of the students in class met the success criterion, which accounts for 47.8% of the class. The difference was not statistically significant (t(22) = -1.2, p >', '< 0.001).\\n\\nFor the second class, the average was 42.4% ± 10.4%. One of the students (5.6%) exceeded the success criterion. The result was statistically significant (t(17) = -5.18, p < 0.001). In the post-test, the class average was 55.3% ± 13.4%. 9 students (50%) were able to meet the criterion of success. The result was statistically significant (t(17) = -2.15, p < 0.05). The overall difference between the tests identified a 12.8% improvement of the results, which was statistically significant (t(17) , p < 0.025).\\n\\nIn the third class, the average of the pretest was 48.3% ± 6.8%, with two out of 29 students meeting the success criterion (6.9% of the total). The difference was statistically significant (t(28) = -6,26, p < 0.001). The post-test results demonstrated an average of 58.1% ± 8.7% of success, with 12 of 29 students being able to meet the criterion (41.4%). The difference was statistically significant (t(28) = -2.7, p < 0.025). The change between the pre-test and post-test scores is characterized as a 9.8% improvement, which is a statistically significant result (t(28), p < 0.05.\\n\\nIn the fourth class, 51.4% ± 9.4% class average was observed. Three out of twenty students were able to meet the success criterion. The difference was statistically significant (t(19) = -3.88, p < 0.005). The post-test indicated an average of 61.5% ± 9% of the class average, with 9 out of 20 students being able to succeed (45%), with no statistically significant difference between the score and the criterion of success (t(19) = -1.85, p >', '< 0.025).\\n\\nIn the fifth class, the calculated average was 51.1% ± 8.8%. Of the 21 students, two met the success criterion (9.5%). The difference was statistically significant (t(20) = -4.23, p < 0.001). In the post-test, the calculated average was 60.6% ± 7.1%, with eight out of 21 students succeeding in obtaining 70% of the score (38.1%). The difference was statistically significant (t(20) = -2.61, p < 0.025). The difference of 9.5% between the pre-test and post-test did not demonstrate sufficient statistical significance (t(20), p >']\n",
      "['< P Earth ; P Earth ≤ PERIOD ≤ P Jupiter ; P >']\n",
      "['<…>', '<…>']\n",
      "['<…>']\n",
      "['<…>']\n",
      "['<0.005), df =27 at a 95% Cl (-1.751, 1.085). With regards to the t-test sig of (0.633>']\n",
      "['<0.05), thus the means score between them are insignificant statistically. The results are 95% Cl (-5.196, -1.869), and the means difference between the groups falls within the t-score values. Table 2 demonstrates no significant differences between the equality in means of the groups AgCC (n=28) and TD (n=32) by the Backward Digit Span Standard Score at 7 years with the Levene’s test with AgCC (n=28) and TD (N=32) at (F=1.187, Sig=0.280 >', '<0.005), df =27 at a 95% Cl (-1.751, 1.085). Regarding the t-test sig of (0.633>']\n",
      "['< [email protected] >']\n"
     ]
    }
   ],
   "source": [
    "# checking existance of any html tags. Reg expression does not detect just html tags so will not remove these tags for fear of losing valuable text within\n",
    "# using beautiful soup to remove tags\n",
    "count = 0\n",
    "for idx, row in df.iterrows():\n",
    "    if re.findall('<.*?>', row['text']) != []:\n",
    "        print(re.findall('<[^>]+>', row['text']))\n",
    "        count = count + 1\n",
    "        if count == 20:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7060a37a-06c4-49b7-a5c4-21f083abc2b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<LongWritable,Text,Text,IntWritable>', '<Text,IntWritable,Text,IntWritable>']\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    if re.findall('<.*?>', row['text']) != []:\n",
    "        print(re.findall('<[^>]+>', row['text']))\n",
    "        soup = BeautifulSoup(row['text'], \"html.parser\")\n",
    "        print(soup.get_text() == row['text'])\n",
    "        \n",
    "        if count == 20:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7b1ee25-ffbd-4a35-9c51-31d463b9f4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\S'\n",
      "C:\\Users\\jarod\\AppData\\Local\\Temp\\ipykernel_55244\\4290813533.py:4: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  if re.findall('https?://\\S+|www\\.\\S+', row['text']) != []:\n",
      "C:\\Users\\jarod\\AppData\\Local\\Temp\\ipykernel_55244\\4290813533.py:5: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  print(re.findall('https?://\\S+|www\\.\\S+', row['text']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.youtube.com/watch?v=j71Kmxv7smk', 'https://www.icas.com/students/learning-blog/test-of-competence/financial-accounting-whats-the-dealclip-with-debits-and-credits']\n",
      "['www.intechopen.com.']\n",
      "['https://doi.org/10.1108/JFC-04-2020-0055']\n",
      "['https://www.nike.com/experiences/details/140585', 'https://www.facebook.com/nike/videos/353688522272944/', 'https://www.launchmetrics.com/resources/blog/nike-data-analysis']\n",
      "['www.youth.gov,']\n",
      "['www.aplaceformom.com.', 'www.hhs.gov']\n",
      "['https://www.fireengineering.com/firefighting/a-guide-to-selecting-the-attack-line/#gref']\n",
      "['https://www.youtube.com/watch?v=0jltioeaEyY']\n",
      "['https://www.facebook.com/profile.php?id=100074386628222', 'https://twitter.com/account/access?did_not_receive=true']\n",
      "['https://www.youtube.com/watch?v=Yqkt54B-JIc']\n",
      "['www.redoliveculture.com.', 'www.americansforthearts.org.', 'www.indiegogo.com.']\n",
      "['https://adoptioncouncil.org/', 'https://chsfl.org/']\n",
      "['www.uschamber.com']\n",
      "['https://www.cnbc.com/2021/01/22/countries-look-to-acquire-the-ip-of-vaccine-makers-to-fight-pandemic.html']\n",
      "['www.ancient-egypt-online.com).', 'www.notredamecathedralparis.com).', 'www.leonardodavinci.net/the-vitruvian-man.jsp).']\n",
      "['www.ouruniversity.com.']\n",
      "['www.journals.lww.com,']\n",
      "['www.chinadaily.com.cn/world/2007-09/13/content-6101963.htm).', 'www.gallup.com/poll/104212/many-consumers-see-Recession-Depression.aspx-).', 'www.gartner.com/DisplayDocument?id=594710-).', 'www.chinadaily.com.cn/world/2008-02/25/content-6483170.htm.)', 'www.msnbc.msn.com/id/17343814/).', 'www.economist.com/opinion/displaystory.cfm?story_id=10134118).']\n",
      "['www.pql.se).']\n",
      "['https://www.alia.org.au/about-alia/policies-standards-and-guidelines/libraries-and-information-services-and-indigenous-peoples)', 'https://atsilirn.aiatsis.gov.au/protocols.php)']\n"
     ]
    }
   ],
   "source": [
    "# checking existance of any urls\n",
    "count = 0\n",
    "for idx, row in df.iterrows():\n",
    "    if re.findall('https?://\\S+|www\\.\\S+', row['text']) != []:\n",
    "        print(re.findall('https?://\\S+|www\\.\\S+', row['text']))\n",
    "        count = count + 1\n",
    "        if count == 20:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49181152-057b-48b2-b5d9-41c9f84b446d",
   "metadata": {},
   "source": [
    "## Resample Data (current size of data causing pre-processing to take too long to execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6707b853-04e3-41f4-bd56-f60a4b6bf8fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.utils import resample\\ndf_downsample = resample(df,\\n             replace=True,\\n             n_samples=364376, # number of ai samples in the dataset\\n             random_state=42)\\n\\nprint(df_downsample.shape)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIX THIS WITH ACCURATE RESAMPLING SIZE\n",
    "\n",
    "'''from sklearn.utils import resample\n",
    "df_downsample = resample(df,\n",
    "             replace=True,\n",
    "             n_samples=364376, # number of ai samples in the dataset\n",
    "             random_state=42)\n",
    "\n",
    "print(df_downsample.shape)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebc9051-b3a0-40de-a2cf-76b1bcee67c8",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0d30016-a196-4d1c-81d4-4fd34a38ed84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\jarod\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jarod\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# functions for preprocessing\n",
    "def remove_urls(text):\n",
    "    return re.sub(r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\", \" \", text) # regex taken from https://www.geeksforgeeks.org/python-check-url-string/\n",
    "\n",
    "def remove_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def remove_extra_whitespace(text):\n",
    "    text = text.strip()\n",
    "    text = \" \".join(text.split())\n",
    "    return text\n",
    "\n",
    "def tokenize_pre_process(text): # for preprocessing using this link: https://spotintelligence.com/2022/12/21/nltk-preprocessing-pipeline/\n",
    "    # tokenize\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    # tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # remove stop words\n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "    tokens = [token for token in tokens if token not in stopwords]\n",
    "\n",
    "    # remove top 10% most frequent words \n",
    "    fdist = nltk.FreqDist(tokens)\n",
    "    tokens = [token for token in tokens if fdist[token] < fdist.N() * 0.1]\n",
    "\n",
    "    # stemming\n",
    "    stemmer = nltk.stem.PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    # eliminate punctuation\n",
    "    tokens = [token for token in tokens if token not in string.punctuation]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "\n",
    "def justTokenize(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    # tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "def sentTokenize(text):\n",
    "    return nltk.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ed49486",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stopwords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m stop_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(stopwords\u001b[38;5;241m.\u001b[39mwords(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      2\u001b[0m punctuation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(string\u001b[38;5;241m.\u001b[39mpunctuation)\n\u001b[0;32m      3\u001b[0m exclude_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m``\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m’\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m“\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m”\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stopwords' is not defined"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "punctuation = set(string.punctuation)\n",
    "exclude_words = set(['``', \"''\", \"'s\", \"n't\", '’', '“', '”'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1684dbbc-1224-4274-b8e7-8b698af6ce0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(df):\n",
    "    # encoding to ascii\n",
    "    df['text'] = df['text'].str.encode('ascii', 'ignore').str.decode('ascii')\n",
    "    \n",
    "    # convert text to lower case\n",
    "    df['text'] = df['text'].str.lower()\n",
    "\n",
    "    # remove html tags \n",
    "    df['text'] = df['text'].apply(remove_html)\n",
    "\n",
    "    # remove urls \n",
    "    df['text'] = df['text'].apply(remove_urls)\n",
    "\n",
    "    # remove extra whitespace\n",
    "    df['text'] = df['text'].apply(remove_extra_whitespace)\n",
    "\n",
    "    # tokenization and further normalization (removing punctuation, frequent words, stop words, and stemming\n",
    "    # df['text'] = df['text'].apply(tokenize_pre_process)\n",
    "    df['text'] = df['text'].apply(justTokenize)\n",
    "\n",
    "    return df\n",
    "\n",
    "def lightProcess(df):\n",
    "    # encoding to ascii\n",
    "    df['text'] = df['text'].str.encode('ascii', 'ignore').str.decode('ascii')\n",
    "    \n",
    "    # convert text to lower case\n",
    "    df['text'] = df['text'].str.lower()\n",
    "\n",
    "    # remove html tags \n",
    "    df['text'] = df['text'].apply(remove_html)\n",
    "\n",
    "    # remove urls \n",
    "    df['text'] = df['text'].apply(remove_urls)\n",
    "\n",
    "    # remove extra whitespace\n",
    "    df['text'] = df['text'].apply(remove_extra_whitespace)\n",
    "\n",
    "    df['text'] = df['text'].replace(\" \", \"\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def sentProcess(df):\n",
    "    # encoding to ascii\n",
    "    df['text'] = df['text'].str.encode('ascii', 'ignore').str.decode('ascii')\n",
    "    \n",
    "    # convert text to lower case\n",
    "    df['text'] = df['text'].str.lower()\n",
    "\n",
    "    # remove html tags \n",
    "    df['text'] = df['text'].apply(remove_html)\n",
    "\n",
    "    # remove urls \n",
    "    df['text'] = df['text'].apply(remove_urls)\n",
    "\n",
    "    # remove extra whitespace\n",
    "    df['text'] = df['text'].apply(remove_extra_whitespace)\n",
    "\n",
    "    # tokenization and further normalization (removing punctuation, frequent words, stop words, and stemming\n",
    "    # df['text'] = df['text'].apply(tokenize_pre_process)\n",
    "    df['text'] = df['text'].apply(sentTokenize)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2aa9456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for Lexical Diversity\n",
    "def avg_word_len(corpus, tokenizedCorpus):\n",
    "    num_char     = len(corpus)   #Total number of characters in text\n",
    "    num_words    = len(tokenizedCorpus) #Total number of words in text\n",
    "    spaces = len(re.findall(r'\\s', corpus))\n",
    "    print(num_words)\n",
    "    print(num_char-spaces)\n",
    "    avg_word_len = (num_char-spaces)/num_words #Average number of characters per word \n",
    "    return avg_word_len\n",
    "\n",
    "def avg_sent_len(tokenizedCorpus, sentTokenizedCorpus):\n",
    "    num_words = len(tokenizedCorpus)\n",
    "    num_sent = len(sentTokenizedCorpus)\n",
    "    avg_sent_len = (num_words)/(num_sent)\n",
    "    return avg_sent_len\n",
    "\n",
    "# Lexical Diversity Score\n",
    "def lex_div_score(tokenizedCorpus):\n",
    "    num_words = len(tokenizedCorpus) #Total number of words in text\n",
    "    num_vocab = len(set(tokenizedCorpus )) #Total number of vocabulary items\n",
    "    avg_vocab = num_vocab/num_words\n",
    "    return avg_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c41269c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jarod\\AppData\\Local\\Temp\\ipykernel_55244\\3677191008.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].str.encode('ascii', 'ignore').str.decode('ascii')\n",
      "C:\\Users\\jarod\\AppData\\Local\\Temp\\ipykernel_55244\\3677191008.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].str.lower()\n",
      "C:\\Users\\jarod\\AppData\\Local\\Temp\\ipykernel_55244\\3677191008.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].apply(remove_html)\n",
      "C:\\Users\\jarod\\AppData\\Local\\Temp\\ipykernel_55244\\3677191008.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].apply(remove_urls)\n",
      "C:\\Users\\jarod\\AppData\\Local\\Temp\\ipykernel_55244\\3677191008.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].apply(remove_extra_whitespace)\n",
      "C:\\Users\\jarod\\AppData\\Local\\Temp\\ipykernel_55244\\3677191008.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].replace(\" \", \"\")\n",
      "C:\\Users\\jarod\\AppData\\Local\\Temp\\ipykernel_55244\\3677191008.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].str.encode('ascii', 'ignore').str.decode('ascii')\n",
      "C:\\Users\\jarod\\AppData\\Local\\Temp\\ipykernel_55244\\3677191008.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].str.lower()\n",
      "C:\\Users\\jarod\\AppData\\Local\\Temp\\ipykernel_55244\\3677191008.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].apply(remove_html)\n",
      "C:\\Users\\jarod\\AppData\\Local\\Temp\\ipykernel_55244\\3677191008.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].apply(remove_urls)\n",
      "C:\\Users\\jarod\\AppData\\Local\\Temp\\ipykernel_55244\\3677191008.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].apply(remove_extra_whitespace)\n",
      "C:\\Users\\jarod\\AppData\\Local\\Temp\\ipykernel_55244\\3677191008.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].apply(justTokenize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330\n",
      "1787\n"
     ]
    }
   ],
   "source": [
    "print(len(df['text'][0]))\n",
    "testSec1 = df[50:200]\n",
    "testSec2 = df[50:200]\n",
    "\n",
    "df_chars = lightProcess(testSec1)\n",
    "df_words = preprocess_text(testSec2)\n",
    "\n",
    "\n",
    "myID = 100\n",
    "awl = avg_word_len(df_chars['text'][myID], df_words['text'][myID])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad7066fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.415151515151515\n"
     ]
    }
   ],
   "source": [
    "print(awl)\n",
    "# df_itemized['text'][myID]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "447fd2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jarod\\AppData\\Local\\Temp\\ipykernel_55244\\3677191008.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].str.encode('ascii', 'ignore').str.decode('ascii')\n",
      "C:\\Users\\jarod\\AppData\\Local\\Temp\\ipykernel_55244\\3677191008.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].str.lower()\n",
      "C:\\Users\\jarod\\AppData\\Local\\Temp\\ipykernel_55244\\3677191008.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].apply(remove_html)\n",
      "C:\\Users\\jarod\\AppData\\Local\\Temp\\ipykernel_55244\\3677191008.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].apply(remove_urls)\n",
      "C:\\Users\\jarod\\AppData\\Local\\Temp\\ipykernel_55244\\3677191008.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].apply(remove_extra_whitespace)\n",
      "C:\\Users\\jarod\\AppData\\Local\\Temp\\ipykernel_55244\\3677191008.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].apply(justTokenize)\n",
      "C:\\Users\\jarod\\AppData\\Local\\Temp\\ipykernel_55244\\3677191008.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].str.encode('ascii', 'ignore').str.decode('ascii')\n",
      "C:\\Users\\jarod\\AppData\\Local\\Temp\\ipykernel_55244\\3677191008.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].str.lower()\n",
      "C:\\Users\\jarod\\AppData\\Local\\Temp\\ipykernel_55244\\3677191008.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].apply(remove_html)\n",
      "C:\\Users\\jarod\\AppData\\Local\\Temp\\ipykernel_55244\\3677191008.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].apply(remove_urls)\n",
      "C:\\Users\\jarod\\AppData\\Local\\Temp\\ipykernel_55244\\3677191008.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].apply(remove_extra_whitespace)\n",
      "C:\\Users\\jarod\\AppData\\Local\\Temp\\ipykernel_55244\\3677191008.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].apply(sentTokenize)\n"
     ]
    }
   ],
   "source": [
    "# Average Sentence length\n",
    "testSec1 = df[50:200]\n",
    "testSec2 = df[50:200]\n",
    "\n",
    "df_words = preprocess_text(testSec1)\n",
    "df_sents = sentProcess(testSec2)\n",
    "\n",
    "\n",
    "myID = 100\n",
    "asl = avg_sent_len(df_words['text'][myID], df_sents['text'][myID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abbeeb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.36842105263158\n"
     ]
    }
   ],
   "source": [
    "print(asl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d208bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.603030303030303\n"
     ]
    }
   ],
   "source": [
    "diversity = lex_div_score(df_words['text'][myID])\n",
    "print(diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "043b5d2b-2f78-47c3-9536-1bbc04b65fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # normalized_df = preprocess_text(df[:10000])\n",
    "\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# skvectorizer = CountVectorizer()\n",
    "\n",
    "# foo = skvectorizer.fit_transform(df['text'][4000:4500])\n",
    "# # skvectorizer.get_feature_names_out()\n",
    "# # features = skvectorizer.get_feature_names_out()\n",
    "# # for feature in features:\n",
    "# #     print(feature)\n",
    "\n",
    "# bar = foo.toarray()\n",
    "# print(bar[:,34])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da45c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['erykah', 'badu', 'bag', 'ladi', 'song', 'mean', 'context', 'essay', 'select', 'erykah', 'badu', 'bag', 'ladi', 'explor', 'origin', 'version', 'live', 'version', '2018', 'cover', 'nao', 'singer', 'interview', 'erica', 'swift', 'interpret', 'messag', 'origin', 'version', 'present', 'song', 'piec', 'art', 'messag', 'serv', 'context', 'bag', 'ladi', 'offici', 'video', 'live', 'version', 'accentu', 'singer', 'posit', 'reput', 'erykah', 'badu', 'live', 'bag', 'ladi', 'contrast', 'cover', 'version', 'place', 'context', 'explor', 'pillar', 'neo-soul', 'due', 'nao', 'introductori', 'word', 'accent', 'might', 'shift', 'underli', 'messag', 'erykah', 'badu', 'contribut', 'neo-soul', 'bag', 'ladi', 'nao', 'cover', 'soul', 'train', 'award', 'nao', 'cover', 'use', 'novel', 'sound', 'record', 'equip', 'technolog', 'perspect', 'add', 'depth', 'emot', 'song', 'enabl', 'listen', 'distinguish', 'detail', 'perform', 'vocal', 'control', 'techniqu', 'thu', 'technolog', 'influenc', 'way', 'bag', 'ladi', 'perceiv', 'find', 'deepen', 'previou', 'knowledg', 'song', 'learn', 'young', 'neo-soul', 'singer', 'might', 'see', 'work', 'question', 'essenc', 'genr', 'uniqu', 'beauti', 'song', 'research', 'activ', 'also', 'challeng', 'previou', 'percept', 'song', 'mean', 'also', 'demonstr', 'variou', 'interconnect', 'interpret', 'song', 'exist', 'origin', 'intend', 'mean', 'singer', 'explain', 'song', 'person', 'growth', 'mani', 'thing', 'one', 'mind', 'hip', 'onlin', 'peopl', 'perspect', 'howev', 'elabor', 'non-specif', 'messag', 'incorpor', 'transit', 'variou', 'stage', 'life', 'recoveri', 'traumat', 'event', 'instanc', 'swift', 'interpret', 'one', 'get', 'destin', 'next', 'chapter', 'life', 'much', 'baggag', 'understand', 'baggag', 'unresolv', 'psycholog', 'trauma', 'interestingli', 'mean', 'explain', 'bit', 'differ', 'percept', 'previou', 'encount', 'song', 'song', 'reflect', 'take', 'much', 'respons', 'spread', 'oneself', 'thin', 'lead', 'exhaust', 'loneli', 'work', 'cite', 'bag', 'ladi', 'nao', 'cover', 'soul', 'train', 'award', 'youtub', 'upload', 'bet', 'intern', '2018.', 'bag', 'ladi', 'offici', 'video', 'youtub', 'upload', 'erykah', 'badu', 'n.d.', 'erykah', 'badu', 'live', 'bag', 'ladi', 'youtub', 'upload', 'aikan74', 'n.d.', 'hip', 'onlin', 'erykah', 'badu', 'interview', 'hip', '2001.', 'swift', 'erikah', 'learn', 'true', 'mean', 'erykah', 'badu', 'bag', 'ladi', 'sign', 'love', '2019']\n"
     ]
    }
   ],
   "source": [
    "# print(normalized_df['text'][300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2099d75-4b55-4b2e-b178-4b88c8423c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[12, year, slave, analysi, film, essay, 2013, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[20+, social, media, post, idea, radic, simpli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source  id                                               text\n",
       "0       0   0  [12, year, slave, analysi, film, essay, 2013, ...\n",
       "1       0   1  [20+, social, media, post, idea, radic, simpli..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5d132a-b923-4764-a74f-b31bcf9e7cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PatRecEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
