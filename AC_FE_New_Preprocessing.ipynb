{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5db0976e-422a-4861-be36-0d77394a2346",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/alexacole/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alexacole/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/alexacole/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "import sklearn\n",
    "#import spacy\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75b5a047-4688-47da-af77-705569e87c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['source', 'id', 'text'],\n",
       "        num_rows: 1392522\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('artem9k/ai-text-detection-pile')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a85aadf-da6e-49da-a4a7-9987e49b454c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>12 Years a Slave: An Analysis of the Film Essa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>human</td>\n",
       "      <td>1</td>\n",
       "      <td>20+ Social Media Post Ideas to Radically Simpl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>human</td>\n",
       "      <td>2</td>\n",
       "      <td>2022 Russian Invasion of Ukraine in Global Med...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>human</td>\n",
       "      <td>3</td>\n",
       "      <td>533 U.S. 27 (2001) Kyllo v. United States: The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>human</td>\n",
       "      <td>4</td>\n",
       "      <td>A Charles Schwab Corporation Case Essay\\n\\nCha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source  id                                               text\n",
       "0  human   0  12 Years a Slave: An Analysis of the Film Essa...\n",
       "1  human   1  20+ Social Media Post Ideas to Radically Simpl...\n",
       "2  human   2  2022 Russian Invasion of Ukraine in Global Med...\n",
       "3  human   3  533 U.S. 27 (2001) Kyllo v. United States: The...\n",
       "4  human   4  A Charles Schwab Corporation Case Essay\\n\\nCha..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(dataset['train'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc858b14-9dbe-470f-928f-90881e776f13",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32b518de-439b-4bcc-93e2-534898f17a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for preprocessing\n",
    "def remove_urls(text):\n",
    "    return re.sub(r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\", \" \", text) # regex taken from https://www.geeksforgeeks.org/python-check-url-string/\n",
    "\n",
    "def remove_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def remove_extra_whitespace(text):\n",
    "    text = text.strip()\n",
    "    text = \" \".join(text.split())\n",
    "    return text\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "    tokens = [token for token in tokens if token not in stopwords]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def lemmatizer(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    l = nltk.stem.WordNetLemmatizer()\n",
    "    tokens = [l.lemmatize(token) for token in tokens]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def tokenize_pre_process(text): # for preprocessing using this link: https://spotintelligence.com/2022/12/21/nltk-preprocessing-pipeline/\n",
    "    # tokenize\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # remove stop words\n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "    tokens = [token for token in tokens if token not in stopwords]\n",
    "\n",
    "    # remove top 10% most frequent words \n",
    "    fdist = nltk.FreqDist(tokens)\n",
    "    tokens = [token for token in tokens if fdist[token] < fdist.N() * 0.1]\n",
    "\n",
    "    # stemming\n",
    "    stemmer = nltk.stem.PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    # eliminate punctuation\n",
    "    tokens = [token for token in tokens if token not in string.punctuation]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8857fa40-58c8-4c7b-a125-075104c50009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # encoding to ascii\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii')\n",
    "    \n",
    "    # convert text to lower case\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove html tags \n",
    "    text = remove_html(text)\n",
    "\n",
    "    # remove urls \n",
    "    text = remove_urls(text)\n",
    "\n",
    "    # remove extra whitespace\n",
    "    text = remove_extra_whitespace(text)\n",
    "\n",
    "    # remove stop words\n",
    "    text = remove_stop_words(text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1afd640-75a0-4bae-95ce-bc0a5a4b8360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text2(text):\n",
    "    # encoding to ascii\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii')\n",
    "    \n",
    "    # convert text to lower case\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove html tags \n",
    "    text = remove_html(text)\n",
    "\n",
    "    # remove urls \n",
    "    text = remove_urls(text)\n",
    "\n",
    "    # remove extra whitespace\n",
    "    text = remove_extra_whitespace(text)\n",
    "\n",
    "    # remove stop words\n",
    "    text = remove_stop_words(text)\n",
    "\n",
    "    # lemmatize words\n",
    "    text = lemmatizer(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343436b3-c476-4b04-babb-29588e7cb236",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b5910b-2c22-4289-9b51-334e25c0fb26",
   "metadata": {},
   "source": [
    "### TFIDF and Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "294c2ed8-1f0f-4bca-ab6e-5392c1e64b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12b21e42-cb07-4f10-ab2a-c677818219f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(max_df=0.9,min_df=0.1)\n",
    "X = vec.fit_transform(df.text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69e51d74-f9c4-47b5-ac77-9995c56eafea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10', '11', '12', '15', '19', '2017', '2018', '2019', '2020',\n",
       "       '2021', '2022', 'ability', 'able', 'about', 'above', 'access',\n",
       "       'according', 'achieve', 'across', 'act', 'action', 'actions',\n",
       "       'activities', 'activity', 'addition', 'additional', 'additionally',\n",
       "       'address', 'affect', 'affected', 'affects', 'after', 'against',\n",
       "       'age', 'al', 'all', 'allow', 'allowed', 'allows', 'almost',\n",
       "       'already', 'also', 'although', 'always', 'america', 'american',\n",
       "       'americans', 'among', 'an', 'analysis', 'another', 'any',\n",
       "       'approach', 'approaches', 'appropriate', 'are', 'area', 'areas',\n",
       "       'around', 'article', 'aspect', 'aspects', 'associated', 'at',\n",
       "       'attention', 'author', 'available', 'avoid', 'back', 'based',\n",
       "       'basis', 'be', 'became', 'because', 'become', 'becomes', 'been',\n",
       "       'before', 'behavior', 'being', 'believe', 'benefits', 'best',\n",
       "       'better', 'between', 'black', 'body', 'both', 'business', 'but',\n",
       "       'by', 'can', 'cannot', 'care', 'case', 'cases', 'cause', 'caused',\n",
       "       'causes', 'central', 'century', 'certain', 'challenges', 'change',\n",
       "       'changes', 'characteristics', 'children', 'cited', 'citizens',\n",
       "       'clear', 'close', 'come', 'common', 'communication', 'community',\n",
       "       'companies', 'company', 'compared', 'complex', 'concept',\n",
       "       'concerns', 'conclusion', 'condition', 'conditions',\n",
       "       'consequences', 'consider', 'considered', 'considering',\n",
       "       'contents', 'context', 'contribute', 'control', 'cost', 'costs',\n",
       "       'could', 'countries', 'country', 'covid', 'create', 'created',\n",
       "       'creating', 'critical', 'crucial', 'cultural', 'culture',\n",
       "       'current', 'data', 'day', 'decision', 'decisions', 'despite',\n",
       "       'determine', 'develop', 'developed', 'developing', 'development',\n",
       "       'did', 'differences', 'different', 'difficult', 'direct',\n",
       "       'directly', 'discussion', 'disease', 'do', 'does', 'due', 'during',\n",
       "       'each', 'early', 'economic', 'education', 'effect', 'effective',\n",
       "       'effectively', 'effects', 'elements', 'employees', 'end', 'enough',\n",
       "       'ensure', 'environment', 'especially', 'essay', 'essential',\n",
       "       'established', 'et', 'even', 'events', 'every', 'everyone',\n",
       "       'evidence', 'example', 'existing', 'experience', 'face', 'fact',\n",
       "       'factor', 'factors', 'family', 'features', 'feel', 'few', 'field',\n",
       "       'finally', 'financial', 'find', 'first', 'five', 'focus', 'follow',\n",
       "       'following', 'food', 'form', 'forms', 'found', 'framework', 'free',\n",
       "       'from', 'full', 'further', 'furthermore', 'future', 'general',\n",
       "       'get', 'give', 'given', 'global', 'go', 'goal', 'goals', 'good',\n",
       "       'government', 'great', 'group', 'groups', 'growth', 'had', 'hand',\n",
       "       'has', 'have', 'having', 'he', 'health', 'healthcare', 'help',\n",
       "       'helps', 'hence', 'her', 'high', 'higher', 'highly', 'him', 'his',\n",
       "       'history', 'home', 'how', 'however', 'human', 'idea', 'ideas',\n",
       "       'identify', 'if', 'impact', 'importance', 'important', 'improve',\n",
       "       'include', 'includes', 'including', 'increase', 'increased',\n",
       "       'increasing', 'individual', 'individuals', 'industry', 'influence',\n",
       "       'information', 'instance', 'instead', 'interest', 'international',\n",
       "       'into', 'introduction', 'involved', 'issue', 'issues', 'its',\n",
       "       'itself', 'journal', 'just', 'key', 'know', 'knowledge', 'known',\n",
       "       'lack', 'large', 'last', 'later', 'law', 'lead', 'leading',\n",
       "       'leads', 'learning', 'led', 'legal', 'less', 'level', 'levels',\n",
       "       'life', 'like', 'likely', 'limited', 'live', 'lives', 'living',\n",
       "       'local', 'long', 'low', 'lower', 'made', 'main', 'maintain',\n",
       "       'major', 'make', 'makes', 'making', 'man', 'management', 'many',\n",
       "       'market', 'matter', 'may', 'me', 'meaning', 'means', 'measures',\n",
       "       'media', 'medical', 'members', 'mental', 'mentioned', 'method',\n",
       "       'methods', 'might', 'model', 'modern', 'money', 'more', 'moreover',\n",
       "       'most', 'much', 'multiple', 'must', 'my', 'national', 'natural',\n",
       "       'nature', 'necessary', 'need', 'needed', 'needs', 'negative',\n",
       "       'never', 'new', 'next', 'no', 'non', 'not', 'now', 'number',\n",
       "       'numerous', 'often', 'one', 'ones', 'only', 'operations',\n",
       "       'opinion', 'opportunities', 'opportunity', 'or', 'order',\n",
       "       'organization', 'organizations', 'other', 'others', 'our', 'out',\n",
       "       'outcomes', 'over', 'overall', 'own', 'pandemic', 'paper', 'part',\n",
       "       'particular', 'particularly', 'past', 'patient', 'patients',\n",
       "       'people', 'performance', 'period', 'person', 'personal',\n",
       "       'perspective', 'physical', 'place', 'plan', 'play', 'point',\n",
       "       'policy', 'political', 'population', 'position', 'positive',\n",
       "       'possible', 'potential', 'power', 'pp', 'practice', 'practices',\n",
       "       'present', 'presented', 'prevent', 'primary', 'principles',\n",
       "       'problem', 'problems', 'process', 'processes', 'product',\n",
       "       'production', 'products', 'professional', 'promote', 'proper',\n",
       "       'provide', 'provided', 'provides', 'providing', 'public',\n",
       "       'purpose', 'quality', 'question', 'range', 'rate', 'rather',\n",
       "       'real', 'reason', 'reasons', 'receive', 'reduce', 'reference',\n",
       "       'references', 'regarding', 'related', 'relationship',\n",
       "       'relationships', 'relevant', 'report', 'require', 'required',\n",
       "       'requires', 'research', 'resources', 'responsibility',\n",
       "       'responsible', 'result', 'results', 'review', 'right', 'rights',\n",
       "       'risk', 'risks', 'role', 'safety', 'same', 'science', 'second',\n",
       "       'security', 'see', 'seen', 'self', 'service', 'services', 'set',\n",
       "       'several', 'severe', 'share', 'she', 'should', 'show', 'shows',\n",
       "       'significant', 'significantly', 'similar', 'since', 'situation',\n",
       "       'skills', 'small', 'so', 'social', 'society', 'some', 'source',\n",
       "       'sources', 'specific', 'spread', 'state', 'states', 'status',\n",
       "       'still', 'story', 'strategies', 'strategy', 'strong', 'structure',\n",
       "       'studies', 'study', 'subject', 'success', 'successful', 'such',\n",
       "       'support', 'system', 'systems', 'table', 'take', 'taken', 'taking',\n",
       "       'technology', 'term', 'terms', 'than', 'their', 'them',\n",
       "       'themselves', 'then', 'theory', 'there', 'therefore', 'these',\n",
       "       'they', 'third', 'this', 'those', 'though', 'three', 'through',\n",
       "       'throughout', 'thus', 'time', 'times', 'today', 'together',\n",
       "       'topic', 'towards', 'treatment', 'turn', 'two', 'type', 'types',\n",
       "       'under', 'understand', 'understanding', 'unique', 'united',\n",
       "       'university', 'up', 'us', 'use', 'used', 'uses', 'using',\n",
       "       'usually', 'value', 'values', 'various', 'very', 'view', 'vital',\n",
       "       'want', 'was', 'way', 'ways', 'we', 'web', 'well', 'were', 'what',\n",
       "       'when', 'where', 'whether', 'which', 'while', 'white', 'who',\n",
       "       'whole', 'why', 'will', 'within', 'without', 'women', 'words',\n",
       "       'work', 'workers', 'working', 'works', 'world', 'would', 'year',\n",
       "       'years', 'you', 'young'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f22d6b9-f08c-4ac8-a8fa-6598f213a5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec2 = CountVectorizer(preprocessor=preprocess_text,max_df=0.9,min_df=0.1)\n",
    "X2 = vec2.fit_transform(df.text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be6ff840-a8e5-4cfe-86ec-2eefd27edc34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10', '11', '12', '15', '19', '2017', '2018', '2019', '2020',\n",
       "       '2021', '2022', 'ability', 'able', 'access', 'according',\n",
       "       'achieve', 'across', 'act', 'action', 'actions', 'activities',\n",
       "       'activity', 'addition', 'additional', 'additionally', 'address',\n",
       "       'affect', 'affected', 'affects', 'age', 'al', 'allow', 'allowed',\n",
       "       'allows', 'almost', 'already', 'also', 'although', 'always',\n",
       "       'america', 'american', 'americans', 'among', 'analysis', 'another',\n",
       "       'approach', 'approaches', 'appropriate', 'area', 'areas', 'around',\n",
       "       'article', 'aspect', 'aspects', 'associated', 'attention',\n",
       "       'author', 'authors', 'available', 'avoid', 'back', 'based',\n",
       "       'basis', 'became', 'become', 'becomes', 'behavior', 'believe',\n",
       "       'benefits', 'best', 'better', 'body', 'business', 'care', 'case',\n",
       "       'cases', 'cause', 'caused', 'causes', 'central', 'century',\n",
       "       'certain', 'challenges', 'change', 'changes', 'characteristics',\n",
       "       'children', 'cited', 'citizens', 'clear', 'close', 'come',\n",
       "       'common', 'communication', 'community', 'companies', 'company',\n",
       "       'companys', 'compared', 'complex', 'concept', 'concerns',\n",
       "       'conclusion', 'condition', 'conditions', 'consequences',\n",
       "       'consider', 'considered', 'considering', 'contents', 'context',\n",
       "       'contribute', 'control', 'cost', 'costs', 'could', 'countries',\n",
       "       'country', 'covid', 'create', 'created', 'creating', 'critical',\n",
       "       'crucial', 'cultural', 'culture', 'current', 'data', 'day',\n",
       "       'decision', 'decisions', 'despite', 'determine', 'develop',\n",
       "       'developed', 'developing', 'development', 'differences',\n",
       "       'different', 'difficult', 'direct', 'directly', 'discussion',\n",
       "       'disease', 'due', 'early', 'economic', 'education', 'effect',\n",
       "       'effective', 'effectively', 'effects', 'elements', 'employees',\n",
       "       'end', 'enough', 'ensure', 'environment', 'especially', 'essay',\n",
       "       'essential', 'established', 'et', 'even', 'events', 'every',\n",
       "       'evidence', 'example', 'existing', 'experience', 'face', 'fact',\n",
       "       'factor', 'factors', 'family', 'features', 'feel', 'field',\n",
       "       'finally', 'financial', 'find', 'first', 'five', 'focus', 'follow',\n",
       "       'following', 'food', 'form', 'forms', 'found', 'framework', 'free',\n",
       "       'full', 'furthermore', 'future', 'general', 'get', 'give', 'given',\n",
       "       'global', 'go', 'goal', 'goals', 'good', 'government', 'great',\n",
       "       'group', 'groups', 'growth', 'hand', 'health', 'healthcare',\n",
       "       'help', 'helps', 'hence', 'high', 'higher', 'highly', 'history',\n",
       "       'home', 'however', 'human', 'idea', 'ideas', 'identify', 'impact',\n",
       "       'importance', 'important', 'improve', 'include', 'includes',\n",
       "       'including', 'increase', 'increased', 'increasing', 'individual',\n",
       "       'individuals', 'industry', 'influence', 'information', 'instance',\n",
       "       'instead', 'interest', 'international', 'introduction', 'involved',\n",
       "       'issue', 'issues', 'journal', 'key', 'know', 'knowledge', 'known',\n",
       "       'lack', 'large', 'last', 'later', 'law', 'lead', 'leading',\n",
       "       'leads', 'learning', 'led', 'legal', 'less', 'level', 'levels',\n",
       "       'life', 'like', 'likely', 'limited', 'live', 'lives', 'living',\n",
       "       'local', 'long', 'low', 'lower', 'made', 'main', 'maintain',\n",
       "       'major', 'make', 'makes', 'making', 'management', 'many', 'market',\n",
       "       'matter', 'may', 'meaning', 'means', 'measures', 'media',\n",
       "       'medical', 'members', 'mental', 'mentioned', 'method', 'methods',\n",
       "       'might', 'model', 'modern', 'money', 'moreover', 'much',\n",
       "       'multiple', 'must', 'national', 'natural', 'nature', 'necessary',\n",
       "       'need', 'needed', 'needs', 'negative', 'never', 'new', 'next',\n",
       "       'non', 'number', 'numerous', 'often', 'one', 'ones', 'operations',\n",
       "       'opinion', 'opportunities', 'opportunity', 'order', 'organization',\n",
       "       'organizations', 'others', 'outcomes', 'overall', 'pandemic',\n",
       "       'paper', 'part', 'particular', 'particularly', 'past', 'patient',\n",
       "       'patients', 'people', 'peoples', 'performance', 'period', 'person',\n",
       "       'personal', 'persons', 'perspective', 'physical', 'place', 'plan',\n",
       "       'play', 'point', 'policy', 'political', 'population', 'position',\n",
       "       'positive', 'possible', 'potential', 'power', 'pp', 'practice',\n",
       "       'practices', 'present', 'presented', 'prevent', 'primary',\n",
       "       'principles', 'problem', 'problems', 'process', 'processes',\n",
       "       'product', 'production', 'products', 'professional', 'programs',\n",
       "       'promote', 'proper', 'provide', 'provided', 'provides',\n",
       "       'providing', 'public', 'purpose', 'quality', 'question', 'range',\n",
       "       'rate', 'rather', 'real', 'reason', 'reasons', 'receive', 'reduce',\n",
       "       'reference', 'references', 'regarding', 'related', 'relationship',\n",
       "       'relationships', 'relevant', 'report', 'require', 'required',\n",
       "       'requires', 'research', 'resources', 'responsibility',\n",
       "       'responsible', 'result', 'results', 'review', 'right', 'rights',\n",
       "       'risk', 'risks', 'role', 'safety', 'science', 'second', 'security',\n",
       "       'see', 'seen', 'self', 'service', 'services', 'set', 'several',\n",
       "       'severe', 'share', 'show', 'shows', 'significant', 'significantly',\n",
       "       'similar', 'since', 'situation', 'skills', 'small', 'social',\n",
       "       'society', 'source', 'sources', 'specific', 'spread', 'state',\n",
       "       'states', 'status', 'still', 'strategies', 'strategy', 'strong',\n",
       "       'structure', 'studies', 'study', 'subject', 'success',\n",
       "       'successful', 'support', 'system', 'systems', 'table', 'take',\n",
       "       'taken', 'taking', 'technology', 'term', 'terms', 'theory',\n",
       "       'therefore', 'third', 'though', 'three', 'throughout', 'thus',\n",
       "       'time', 'times', 'together', 'topic', 'towards', 'treatment',\n",
       "       'turn', 'two', 'type', 'types', 'understand', 'understanding',\n",
       "       'unique', 'united', 'university', 'us', 'use', 'used', 'uses',\n",
       "       'using', 'usually', 'value', 'values', 'various', 'view', 'vital',\n",
       "       'want', 'way', 'ways', 'web', 'well', 'whether', 'white', 'whole',\n",
       "       'within', 'without', 'women', 'words', 'work', 'workers',\n",
       "       'working', 'works', 'world', 'would', 'year', 'years', 'young'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec2.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "babe2fe5-7e00-49a3-928d-4dae81182844",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec3 = CountVectorizer(preprocessor=preprocess_text2,max_df=0.9,min_df=0.1)\n",
    "X3 = vec3.fit_transform(df.text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4165a5c5-cea7-42fc-9d2a-fd5f1e413640",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10', '11', '12', '15', '19', '2017', '2018', '2019', '2020',\n",
       "       '2021', '2022', 'ability', 'able', 'access', 'according',\n",
       "       'account', 'achieve', 'across', 'act', 'action', 'activity',\n",
       "       'addition', 'additional', 'additionally', 'address', 'advantage',\n",
       "       'affect', 'affected', 'age', 'aim', 'al', 'allow', 'allowed',\n",
       "       'allows', 'almost', 'already', 'also', 'although', 'always',\n",
       "       'america', 'american', 'among', 'amount', 'analysis', 'another',\n",
       "       'application', 'approach', 'appropriate', 'area', 'around',\n",
       "       'article', 'aspect', 'assessment', 'associated', 'attention',\n",
       "       'attitude', 'author', 'authority', 'available', 'avoid', 'back',\n",
       "       'background', 'based', 'basis', 'became', 'become', 'becomes',\n",
       "       'behavior', 'being', 'belief', 'believe', 'benefit', 'best',\n",
       "       'better', 'black', 'body', 'book', 'business', 'care', 'case',\n",
       "       'cause', 'caused', 'center', 'central', 'century', 'certain',\n",
       "       'challenge', 'chance', 'change', 'character', 'characteristic',\n",
       "       'child', 'choice', 'cited', 'citizen', 'claim', 'clear', 'close',\n",
       "       'come', 'common', 'communication', 'community', 'company',\n",
       "       'compared', 'complex', 'component', 'concept', 'concern',\n",
       "       'conclusion', 'condition', 'conduct', 'conflict', 'connection',\n",
       "       'consequence', 'consider', 'consideration', 'considered',\n",
       "       'considering', 'content', 'context', 'contribute', 'control',\n",
       "       'cost', 'could', 'country', 'covid', 'create', 'created',\n",
       "       'creating', 'critical', 'crucial', 'cultural', 'culture',\n",
       "       'current', 'customer', 'data', 'day', 'death', 'decision',\n",
       "       'demand', 'desire', 'despite', 'detail', 'determine', 'develop',\n",
       "       'developed', 'developing', 'development', 'difference',\n",
       "       'different', 'difficult', 'direct', 'directly', 'discussion',\n",
       "       'disease', 'due', 'early', 'economic', 'ed', 'education', 'effect',\n",
       "       'effective', 'effectively', 'effort', 'element', 'employee', 'end',\n",
       "       'enough', 'ensure', 'environment', 'especially', 'essay',\n",
       "       'essential', 'established', 'et', 'even', 'event', 'every',\n",
       "       'evidence', 'example', 'existing', 'experience', 'face', 'fact',\n",
       "       'factor', 'family', 'feature', 'feel', 'feeling', 'field',\n",
       "       'finally', 'financial', 'find', 'finding', 'first', 'five',\n",
       "       'focus', 'follow', 'following', 'food', 'force', 'form', 'found',\n",
       "       'framework', 'free', 'full', 'function', 'furthermore', 'future',\n",
       "       'general', 'get', 'give', 'given', 'global', 'go', 'goal', 'good',\n",
       "       'government', 'great', 'group', 'growth', 'hand', 'health',\n",
       "       'healthcare', 'help', 'hence', 'high', 'higher', 'highly',\n",
       "       'history', 'home', 'however', 'human', 'idea', 'identify', 'image',\n",
       "       'impact', 'importance', 'important', 'improve', 'improvement',\n",
       "       'include', 'includes', 'including', 'income', 'increase',\n",
       "       'increased', 'increasing', 'individual', 'industry', 'influence',\n",
       "       'information', 'instance', 'instead', 'interaction', 'interest',\n",
       "       'international', 'introduction', 'involved', 'issue', 'job',\n",
       "       'journal', 'keep', 'key', 'know', 'knowledge', 'known', 'lack',\n",
       "       'large', 'last', 'later', 'law', 'lead', 'leader', 'leading',\n",
       "       'learning', 'led', 'legal', 'less', 'level', 'life', 'like',\n",
       "       'likely', 'limited', 'live', 'living', 'local', 'long', 'look',\n",
       "       'loss', 'low', 'lower', 'made', 'main', 'maintain', 'major',\n",
       "       'make', 'making', 'man', 'management', 'many', 'market',\n",
       "       'material', 'matter', 'may', 'mean', 'meaning', 'measure',\n",
       "       'medical', 'medicine', 'medium', 'meet', 'member', 'mental',\n",
       "       'mentioned', 'method', 'might', 'million', 'model', 'modern',\n",
       "       'money', 'moreover', 'movement', 'much', 'multiple', 'must',\n",
       "       'national', 'natural', 'nature', 'necessary', 'need', 'needed',\n",
       "       'negative', 'never', 'new', 'next', 'non', 'note', 'number',\n",
       "       'numerous', 'objective', 'offer', 'often', 'one', 'open',\n",
       "       'operation', 'opinion', 'opportunity', 'order', 'organization',\n",
       "       'others', 'outcome', 'overall', 'pandemic', 'paper', 'part',\n",
       "       'particular', 'particularly', 'past', 'patient', 'pay', 'people',\n",
       "       'perception', 'performance', 'period', 'person', 'personal',\n",
       "       'perspective', 'physical', 'place', 'plan', 'play', 'point',\n",
       "       'policy', 'political', 'population', 'position', 'positive',\n",
       "       'possibility', 'possible', 'potential', 'power', 'pp', 'practice',\n",
       "       'present', 'presented', 'press', 'prevent', 'primary', 'principle',\n",
       "       'problem', 'process', 'product', 'production', 'professional',\n",
       "       'program', 'project', 'promote', 'proper', 'provide', 'provided',\n",
       "       'provides', 'providing', 'public', 'purpose', 'put', 'quality',\n",
       "       'question', 'range', 'rate', 'rather', 'real', 'reason', 'receive',\n",
       "       'reduce', 'reference', 'regarding', 'related', 'relation',\n",
       "       'relationship', 'relevant', 'report', 'require', 'required',\n",
       "       'requires', 'research', 'researcher', 'resource', 'response',\n",
       "       'responsibility', 'responsible', 'result', 'review', 'right',\n",
       "       'risk', 'role', 'rule', 'safety', 'say', 'science', 'second',\n",
       "       'security', 'see', 'seen', 'self', 'service', 'set', 'setting',\n",
       "       'several', 'severe', 'share', 'show', 'side', 'significant',\n",
       "       'significantly', 'similar', 'since', 'situation', 'skill', 'small',\n",
       "       'social', 'society', 'solution', 'source', 'specific', 'spread',\n",
       "       'stage', 'standard', 'start', 'state', 'statement', 'status',\n",
       "       'step', 'still', 'story', 'strategy', 'strong', 'structure',\n",
       "       'study', 'subject', 'success', 'successful', 'support', 'system',\n",
       "       'table', 'take', 'taken', 'taking', 'task', 'technology', 'term',\n",
       "       'theory', 'therefore', 'thing', 'think', 'third', 'though',\n",
       "       'thought', 'threat', 'three', 'throughout', 'thus', 'time',\n",
       "       'today', 'together', 'tool', 'topic', 'towards', 'treatment',\n",
       "       'trend', 'turn', 'two', 'type', 'understand', 'understanding',\n",
       "       'unique', 'united', 'university', 'us', 'use', 'used', 'using',\n",
       "       'usually', 'value', 'various', 'view', 'vital', 'want', 'way',\n",
       "       'web', 'well', 'whether', 'white', 'whole', 'within', 'without',\n",
       "       'woman', 'word', 'work', 'worker', 'working', 'world', 'would',\n",
       "       'writing', 'year', 'young'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec3.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368a78d5-0e20-4500-8d23-7bac8accebf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b505b72-5113-4ebc-945d-17283978efdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
