{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5db0976e-422a-4861-be36-0d77394a2346",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\color\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\color\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\color\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "import sklearn\n",
    "#import spacy\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75b5a047-4688-47da-af77-705569e87c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['source', 'id', 'text'],\n",
       "        num_rows: 1392522\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('artem9k/ai-text-detection-pile')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a85aadf-da6e-49da-a4a7-9987e49b454c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>12 Years a Slave: An Analysis of the Film Essa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>human</td>\n",
       "      <td>1</td>\n",
       "      <td>20+ Social Media Post Ideas to Radically Simpl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>human</td>\n",
       "      <td>2</td>\n",
       "      <td>2022 Russian Invasion of Ukraine in Global Med...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>human</td>\n",
       "      <td>3</td>\n",
       "      <td>533 U.S. 27 (2001) Kyllo v. United States: The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>human</td>\n",
       "      <td>4</td>\n",
       "      <td>A Charles Schwab Corporation Case Essay\\n\\nCha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source  id                                               text\n",
       "0  human   0  12 Years a Slave: An Analysis of the Film Essa...\n",
       "1  human   1  20+ Social Media Post Ideas to Radically Simpl...\n",
       "2  human   2  2022 Russian Invasion of Ukraine in Global Med...\n",
       "3  human   3  533 U.S. 27 (2001) Kyllo v. United States: The...\n",
       "4  human   4  A Charles Schwab Corporation Case Essay\\n\\nCha..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(dataset['train'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc858b14-9dbe-470f-928f-90881e776f13",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32b518de-439b-4bcc-93e2-534898f17a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for preprocessing\n",
    "def remove_urls(text):\n",
    "    return re.sub(r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\", \" \", text) # regex taken from https://www.geeksforgeeks.org/python-check-url-string/\n",
    "\n",
    "def remove_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def remove_extra_whitespace(text):\n",
    "    text = text.strip()\n",
    "    text = \" \".join(text.split())\n",
    "    return text\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "    tokens = [token for token in tokens if token not in stopwords]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def lemmatizer(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    l = nltk.stem.WordNetLemmatizer()\n",
    "    tokens = [l.lemmatize(token) for token in tokens]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def tokenize_pre_process(text): # for preprocessing using this link: https://spotintelligence.com/2022/12/21/nltk-preprocessing-pipeline/\n",
    "    # tokenize\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # remove stop words\n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "    tokens = [token for token in tokens if token not in stopwords]\n",
    "\n",
    "    # remove top 10% most frequent words \n",
    "    fdist = nltk.FreqDist(tokens)\n",
    "    tokens = [token for token in tokens if fdist[token] < fdist.N() * 0.1]\n",
    "\n",
    "    # stemming\n",
    "    stemmer = nltk.stem.PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    # eliminate punctuation\n",
    "    tokens = [token for token in tokens if token not in string.punctuation]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8857fa40-58c8-4c7b-a125-075104c50009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # encoding to ascii\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii')\n",
    "    \n",
    "    # convert text to lower case\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove html tags \n",
    "    text = remove_html(text)\n",
    "\n",
    "    # remove urls \n",
    "    text = remove_urls(text)\n",
    "\n",
    "    # remove extra whitespace\n",
    "    text = remove_extra_whitespace(text)\n",
    "\n",
    "    # remove stop words\n",
    "    text = remove_stop_words(text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1afd640-75a0-4bae-95ce-bc0a5a4b8360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text2(text):\n",
    "    # encoding to ascii\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii')\n",
    "    \n",
    "    # convert text to lower case\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove html tags \n",
    "    text = remove_html(text)\n",
    "\n",
    "    # remove urls \n",
    "    text = remove_urls(text)\n",
    "\n",
    "    # remove extra whitespace\n",
    "    text = remove_extra_whitespace(text)\n",
    "\n",
    "    # remove stop words\n",
    "    text = remove_stop_words(text)\n",
    "\n",
    "    # lemmatize words\n",
    "    text = lemmatizer(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343436b3-c476-4b04-babb-29588e7cb236",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b5910b-2c22-4289-9b51-334e25c0fb26",
   "metadata": {},
   "source": [
    "### TFIDF and Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "294c2ed8-1f0f-4bca-ab6e-5392c1e64b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12b21e42-cb07-4f10-ab2a-c677818219f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(max_df=0.9,min_df=0.1)\n",
    "X = vec.fit_transform(df.text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69e51d74-f9c4-47b5-ac77-9995c56eafea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10', '11', '12', '15', '19', '2017', '2018', '2019', '2020',\n",
       "       '2021', '2022', 'ability', 'able', 'about', 'above', 'access',\n",
       "       'according', 'achieve', 'across', 'act', 'action', 'actions',\n",
       "       'activities', 'activity', 'addition', 'additional', 'additionally',\n",
       "       'address', 'affect', 'affected', 'affects', 'after', 'against',\n",
       "       'age', 'al', 'all', 'allow', 'allowed', 'allows', 'almost',\n",
       "       'already', 'also', 'although', 'always', 'america', 'american',\n",
       "       'americans', 'among', 'an', 'analysis', 'another', 'any',\n",
       "       'approach', 'approaches', 'appropriate', 'are', 'area', 'areas',\n",
       "       'around', 'article', 'aspect', 'aspects', 'associated', 'at',\n",
       "       'attention', 'author', 'available', 'avoid', 'back', 'based',\n",
       "       'basis', 'be', 'became', 'because', 'become', 'becomes', 'been',\n",
       "       'before', 'behavior', 'being', 'believe', 'benefits', 'best',\n",
       "       'better', 'between', 'black', 'body', 'both', 'business', 'but',\n",
       "       'by', 'can', 'cannot', 'care', 'case', 'cases', 'cause', 'caused',\n",
       "       'causes', 'central', 'century', 'certain', 'challenges', 'change',\n",
       "       'changes', 'characteristics', 'children', 'cited', 'citizens',\n",
       "       'clear', 'close', 'come', 'common', 'communication', 'community',\n",
       "       'companies', 'company', 'compared', 'complex', 'concept',\n",
       "       'concerns', 'conclusion', 'condition', 'conditions',\n",
       "       'consequences', 'consider', 'considered', 'considering',\n",
       "       'contents', 'context', 'contribute', 'control', 'cost', 'costs',\n",
       "       'could', 'countries', 'country', 'covid', 'create', 'created',\n",
       "       'creating', 'critical', 'crucial', 'cultural', 'culture',\n",
       "       'current', 'data', 'day', 'decision', 'decisions', 'despite',\n",
       "       'determine', 'develop', 'developed', 'developing', 'development',\n",
       "       'did', 'differences', 'different', 'difficult', 'direct',\n",
       "       'directly', 'discussion', 'disease', 'do', 'does', 'due', 'during',\n",
       "       'each', 'early', 'economic', 'education', 'effect', 'effective',\n",
       "       'effectively', 'effects', 'elements', 'employees', 'end', 'enough',\n",
       "       'ensure', 'environment', 'especially', 'essay', 'essential',\n",
       "       'established', 'et', 'even', 'events', 'every', 'everyone',\n",
       "       'evidence', 'example', 'existing', 'experience', 'face', 'fact',\n",
       "       'factor', 'factors', 'family', 'features', 'feel', 'few', 'field',\n",
       "       'finally', 'financial', 'find', 'first', 'five', 'focus', 'follow',\n",
       "       'following', 'food', 'form', 'forms', 'found', 'framework', 'free',\n",
       "       'from', 'full', 'further', 'furthermore', 'future', 'general',\n",
       "       'get', 'give', 'given', 'global', 'go', 'goal', 'goals', 'good',\n",
       "       'government', 'great', 'group', 'groups', 'growth', 'had', 'hand',\n",
       "       'has', 'have', 'having', 'he', 'health', 'healthcare', 'help',\n",
       "       'helps', 'hence', 'her', 'high', 'higher', 'highly', 'him', 'his',\n",
       "       'history', 'home', 'how', 'however', 'human', 'idea', 'ideas',\n",
       "       'identify', 'if', 'impact', 'importance', 'important', 'improve',\n",
       "       'include', 'includes', 'including', 'increase', 'increased',\n",
       "       'increasing', 'individual', 'individuals', 'industry', 'influence',\n",
       "       'information', 'instance', 'instead', 'interest', 'international',\n",
       "       'into', 'introduction', 'involved', 'issue', 'issues', 'its',\n",
       "       'itself', 'journal', 'just', 'key', 'know', 'knowledge', 'known',\n",
       "       'lack', 'large', 'last', 'later', 'law', 'lead', 'leading',\n",
       "       'leads', 'learning', 'led', 'legal', 'less', 'level', 'levels',\n",
       "       'life', 'like', 'likely', 'limited', 'live', 'lives', 'living',\n",
       "       'local', 'long', 'low', 'lower', 'made', 'main', 'maintain',\n",
       "       'major', 'make', 'makes', 'making', 'man', 'management', 'many',\n",
       "       'market', 'matter', 'may', 'me', 'meaning', 'means', 'measures',\n",
       "       'media', 'medical', 'members', 'mental', 'mentioned', 'method',\n",
       "       'methods', 'might', 'model', 'modern', 'money', 'more', 'moreover',\n",
       "       'most', 'much', 'multiple', 'must', 'my', 'national', 'natural',\n",
       "       'nature', 'necessary', 'need', 'needed', 'needs', 'negative',\n",
       "       'never', 'new', 'next', 'no', 'non', 'not', 'now', 'number',\n",
       "       'numerous', 'often', 'one', 'ones', 'only', 'operations',\n",
       "       'opinion', 'opportunities', 'opportunity', 'or', 'order',\n",
       "       'organization', 'organizations', 'other', 'others', 'our', 'out',\n",
       "       'outcomes', 'over', 'overall', 'own', 'pandemic', 'paper', 'part',\n",
       "       'particular', 'particularly', 'past', 'patient', 'patients',\n",
       "       'people', 'performance', 'period', 'person', 'personal',\n",
       "       'perspective', 'physical', 'place', 'plan', 'play', 'point',\n",
       "       'policy', 'political', 'population', 'position', 'positive',\n",
       "       'possible', 'potential', 'power', 'pp', 'practice', 'practices',\n",
       "       'present', 'presented', 'prevent', 'primary', 'principles',\n",
       "       'problem', 'problems', 'process', 'processes', 'product',\n",
       "       'production', 'products', 'professional', 'promote', 'proper',\n",
       "       'provide', 'provided', 'provides', 'providing', 'public',\n",
       "       'purpose', 'quality', 'question', 'range', 'rate', 'rather',\n",
       "       'real', 'reason', 'reasons', 'receive', 'reduce', 'reference',\n",
       "       'references', 'regarding', 'related', 'relationship',\n",
       "       'relationships', 'relevant', 'report', 'require', 'required',\n",
       "       'requires', 'research', 'resources', 'responsibility',\n",
       "       'responsible', 'result', 'results', 'review', 'right', 'rights',\n",
       "       'risk', 'risks', 'role', 'safety', 'same', 'science', 'second',\n",
       "       'security', 'see', 'seen', 'self', 'service', 'services', 'set',\n",
       "       'several', 'severe', 'share', 'she', 'should', 'show', 'shows',\n",
       "       'significant', 'significantly', 'similar', 'since', 'situation',\n",
       "       'skills', 'small', 'so', 'social', 'society', 'some', 'source',\n",
       "       'sources', 'specific', 'spread', 'state', 'states', 'status',\n",
       "       'still', 'story', 'strategies', 'strategy', 'strong', 'structure',\n",
       "       'studies', 'study', 'subject', 'success', 'successful', 'such',\n",
       "       'support', 'system', 'systems', 'table', 'take', 'taken', 'taking',\n",
       "       'technology', 'term', 'terms', 'than', 'their', 'them',\n",
       "       'themselves', 'then', 'theory', 'there', 'therefore', 'these',\n",
       "       'they', 'third', 'this', 'those', 'though', 'three', 'through',\n",
       "       'throughout', 'thus', 'time', 'times', 'today', 'together',\n",
       "       'topic', 'towards', 'treatment', 'turn', 'two', 'type', 'types',\n",
       "       'under', 'understand', 'understanding', 'unique', 'united',\n",
       "       'university', 'up', 'us', 'use', 'used', 'uses', 'using',\n",
       "       'usually', 'value', 'values', 'various', 'very', 'view', 'vital',\n",
       "       'want', 'was', 'way', 'ways', 'we', 'web', 'well', 'were', 'what',\n",
       "       'when', 'where', 'whether', 'which', 'while', 'white', 'who',\n",
       "       'whole', 'why', 'will', 'within', 'without', 'women', 'words',\n",
       "       'work', 'workers', 'working', 'works', 'world', 'would', 'year',\n",
       "       'years', 'you', 'young'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f22d6b9-f08c-4ac8-a8fa-6598f213a5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec2 = CountVectorizer(preprocessor=preprocess_text,max_df=0.9,min_df=0.1)\n",
    "X2 = vec2.fit_transform(df.text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be6ff840-a8e5-4cfe-86ec-2eefd27edc34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10', '11', '12', '15', '19', '2017', '2018', '2019', '2020',\n",
       "       '2021', '2022', 'ability', 'able', 'access', 'according',\n",
       "       'achieve', 'across', 'act', 'action', 'actions', 'activities',\n",
       "       'activity', 'addition', 'additional', 'additionally', 'address',\n",
       "       'affect', 'affected', 'affects', 'age', 'al', 'allow', 'allowed',\n",
       "       'allows', 'almost', 'already', 'also', 'although', 'always',\n",
       "       'america', 'american', 'americans', 'among', 'analysis', 'another',\n",
       "       'approach', 'approaches', 'appropriate', 'area', 'areas', 'around',\n",
       "       'article', 'aspect', 'aspects', 'associated', 'attention',\n",
       "       'author', 'authors', 'available', 'avoid', 'back', 'based',\n",
       "       'basis', 'became', 'become', 'becomes', 'behavior', 'believe',\n",
       "       'benefits', 'best', 'better', 'body', 'business', 'care', 'case',\n",
       "       'cases', 'cause', 'caused', 'causes', 'central', 'century',\n",
       "       'certain', 'challenges', 'change', 'changes', 'characteristics',\n",
       "       'children', 'cited', 'citizens', 'clear', 'close', 'come',\n",
       "       'common', 'communication', 'community', 'companies', 'company',\n",
       "       'companys', 'compared', 'complex', 'concept', 'concerns',\n",
       "       'conclusion', 'condition', 'conditions', 'consequences',\n",
       "       'consider', 'considered', 'considering', 'contents', 'context',\n",
       "       'contribute', 'control', 'cost', 'costs', 'could', 'countries',\n",
       "       'country', 'covid', 'create', 'created', 'creating', 'critical',\n",
       "       'crucial', 'cultural', 'culture', 'current', 'data', 'day',\n",
       "       'decision', 'decisions', 'despite', 'determine', 'develop',\n",
       "       'developed', 'developing', 'development', 'differences',\n",
       "       'different', 'difficult', 'direct', 'directly', 'discussion',\n",
       "       'disease', 'due', 'early', 'economic', 'education', 'effect',\n",
       "       'effective', 'effectively', 'effects', 'elements', 'employees',\n",
       "       'end', 'enough', 'ensure', 'environment', 'especially', 'essay',\n",
       "       'essential', 'established', 'et', 'even', 'events', 'every',\n",
       "       'evidence', 'example', 'existing', 'experience', 'face', 'fact',\n",
       "       'factor', 'factors', 'family', 'features', 'feel', 'field',\n",
       "       'finally', 'financial', 'find', 'first', 'five', 'focus', 'follow',\n",
       "       'following', 'food', 'form', 'forms', 'found', 'framework', 'free',\n",
       "       'full', 'furthermore', 'future', 'general', 'get', 'give', 'given',\n",
       "       'global', 'go', 'goal', 'goals', 'good', 'government', 'great',\n",
       "       'group', 'groups', 'growth', 'hand', 'health', 'healthcare',\n",
       "       'help', 'helps', 'hence', 'high', 'higher', 'highly', 'history',\n",
       "       'home', 'however', 'human', 'idea', 'ideas', 'identify', 'impact',\n",
       "       'importance', 'important', 'improve', 'include', 'includes',\n",
       "       'including', 'increase', 'increased', 'increasing', 'individual',\n",
       "       'individuals', 'industry', 'influence', 'information', 'instance',\n",
       "       'instead', 'interest', 'international', 'introduction', 'involved',\n",
       "       'issue', 'issues', 'journal', 'key', 'know', 'knowledge', 'known',\n",
       "       'lack', 'large', 'last', 'later', 'law', 'lead', 'leading',\n",
       "       'leads', 'learning', 'led', 'legal', 'less', 'level', 'levels',\n",
       "       'life', 'like', 'likely', 'limited', 'live', 'lives', 'living',\n",
       "       'local', 'long', 'low', 'lower', 'made', 'main', 'maintain',\n",
       "       'major', 'make', 'makes', 'making', 'management', 'many', 'market',\n",
       "       'matter', 'may', 'meaning', 'means', 'measures', 'media',\n",
       "       'medical', 'members', 'mental', 'mentioned', 'method', 'methods',\n",
       "       'might', 'model', 'modern', 'money', 'moreover', 'much',\n",
       "       'multiple', 'must', 'national', 'natural', 'nature', 'necessary',\n",
       "       'need', 'needed', 'needs', 'negative', 'never', 'new', 'next',\n",
       "       'non', 'number', 'numerous', 'often', 'one', 'ones', 'operations',\n",
       "       'opinion', 'opportunities', 'opportunity', 'order', 'organization',\n",
       "       'organizations', 'others', 'outcomes', 'overall', 'pandemic',\n",
       "       'paper', 'part', 'particular', 'particularly', 'past', 'patient',\n",
       "       'patients', 'people', 'peoples', 'performance', 'period', 'person',\n",
       "       'personal', 'persons', 'perspective', 'physical', 'place', 'plan',\n",
       "       'play', 'point', 'policy', 'political', 'population', 'position',\n",
       "       'positive', 'possible', 'potential', 'power', 'pp', 'practice',\n",
       "       'practices', 'present', 'presented', 'prevent', 'primary',\n",
       "       'principles', 'problem', 'problems', 'process', 'processes',\n",
       "       'product', 'production', 'products', 'professional', 'programs',\n",
       "       'promote', 'proper', 'provide', 'provided', 'provides',\n",
       "       'providing', 'public', 'purpose', 'quality', 'question', 'range',\n",
       "       'rate', 'rather', 'real', 'reason', 'reasons', 'receive', 'reduce',\n",
       "       'reference', 'references', 'regarding', 'related', 'relationship',\n",
       "       'relationships', 'relevant', 'report', 'require', 'required',\n",
       "       'requires', 'research', 'resources', 'responsibility',\n",
       "       'responsible', 'result', 'results', 'review', 'right', 'rights',\n",
       "       'risk', 'risks', 'role', 'safety', 'science', 'second', 'security',\n",
       "       'see', 'seen', 'self', 'service', 'services', 'set', 'several',\n",
       "       'severe', 'share', 'show', 'shows', 'significant', 'significantly',\n",
       "       'similar', 'since', 'situation', 'skills', 'small', 'social',\n",
       "       'society', 'source', 'sources', 'specific', 'spread', 'state',\n",
       "       'states', 'status', 'still', 'strategies', 'strategy', 'strong',\n",
       "       'structure', 'studies', 'study', 'subject', 'success',\n",
       "       'successful', 'support', 'system', 'systems', 'table', 'take',\n",
       "       'taken', 'taking', 'technology', 'term', 'terms', 'theory',\n",
       "       'therefore', 'third', 'though', 'three', 'throughout', 'thus',\n",
       "       'time', 'times', 'together', 'topic', 'towards', 'treatment',\n",
       "       'turn', 'two', 'type', 'types', 'understand', 'understanding',\n",
       "       'unique', 'united', 'university', 'us', 'use', 'used', 'uses',\n",
       "       'using', 'usually', 'value', 'values', 'various', 'view', 'vital',\n",
       "       'want', 'way', 'ways', 'web', 'well', 'whether', 'white', 'whole',\n",
       "       'within', 'without', 'women', 'words', 'work', 'workers',\n",
       "       'working', 'works', 'world', 'would', 'year', 'years', 'young'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec2.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "babe2fe5-7e00-49a3-928d-4dae81182844",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec3 = CountVectorizer(preprocessor=preprocess_text2,max_df=0.9,min_df=0.1)\n",
    "X3 = vec3.fit_transform(df.text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4165a5c5-cea7-42fc-9d2a-fd5f1e413640",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10', '11', '12', '15', '19', '2017', '2018', '2019', '2020',\n",
       "       '2021', '2022', 'ability', 'able', 'access', 'according',\n",
       "       'account', 'achieve', 'across', 'act', 'action', 'activity',\n",
       "       'addition', 'additional', 'additionally', 'address', 'advantage',\n",
       "       'affect', 'affected', 'age', 'aim', 'al', 'allow', 'allowed',\n",
       "       'allows', 'almost', 'already', 'also', 'although', 'always',\n",
       "       'america', 'american', 'among', 'amount', 'analysis', 'another',\n",
       "       'application', 'approach', 'appropriate', 'area', 'around',\n",
       "       'article', 'aspect', 'assessment', 'associated', 'attention',\n",
       "       'attitude', 'author', 'authority', 'available', 'avoid', 'back',\n",
       "       'background', 'based', 'basis', 'became', 'become', 'becomes',\n",
       "       'behavior', 'being', 'belief', 'believe', 'benefit', 'best',\n",
       "       'better', 'black', 'body', 'book', 'business', 'care', 'case',\n",
       "       'cause', 'caused', 'center', 'central', 'century', 'certain',\n",
       "       'challenge', 'chance', 'change', 'character', 'characteristic',\n",
       "       'child', 'choice', 'cited', 'citizen', 'claim', 'clear', 'close',\n",
       "       'come', 'common', 'communication', 'community', 'company',\n",
       "       'compared', 'complex', 'component', 'concept', 'concern',\n",
       "       'conclusion', 'condition', 'conduct', 'conflict', 'connection',\n",
       "       'consequence', 'consider', 'consideration', 'considered',\n",
       "       'considering', 'content', 'context', 'contribute', 'control',\n",
       "       'cost', 'could', 'country', 'covid', 'create', 'created',\n",
       "       'creating', 'critical', 'crucial', 'cultural', 'culture',\n",
       "       'current', 'customer', 'data', 'day', 'death', 'decision',\n",
       "       'demand', 'desire', 'despite', 'detail', 'determine', 'develop',\n",
       "       'developed', 'developing', 'development', 'difference',\n",
       "       'different', 'difficult', 'direct', 'directly', 'discussion',\n",
       "       'disease', 'due', 'early', 'economic', 'ed', 'education', 'effect',\n",
       "       'effective', 'effectively', 'effort', 'element', 'employee', 'end',\n",
       "       'enough', 'ensure', 'environment', 'especially', 'essay',\n",
       "       'essential', 'established', 'et', 'even', 'event', 'every',\n",
       "       'evidence', 'example', 'existing', 'experience', 'face', 'fact',\n",
       "       'factor', 'family', 'feature', 'feel', 'feeling', 'field',\n",
       "       'finally', 'financial', 'find', 'finding', 'first', 'five',\n",
       "       'focus', 'follow', 'following', 'food', 'force', 'form', 'found',\n",
       "       'framework', 'free', 'full', 'function', 'furthermore', 'future',\n",
       "       'general', 'get', 'give', 'given', 'global', 'go', 'goal', 'good',\n",
       "       'government', 'great', 'group', 'growth', 'hand', 'health',\n",
       "       'healthcare', 'help', 'hence', 'high', 'higher', 'highly',\n",
       "       'history', 'home', 'however', 'human', 'idea', 'identify', 'image',\n",
       "       'impact', 'importance', 'important', 'improve', 'improvement',\n",
       "       'include', 'includes', 'including', 'income', 'increase',\n",
       "       'increased', 'increasing', 'individual', 'industry', 'influence',\n",
       "       'information', 'instance', 'instead', 'interaction', 'interest',\n",
       "       'international', 'introduction', 'involved', 'issue', 'job',\n",
       "       'journal', 'keep', 'key', 'know', 'knowledge', 'known', 'lack',\n",
       "       'large', 'last', 'later', 'law', 'lead', 'leader', 'leading',\n",
       "       'learning', 'led', 'legal', 'less', 'level', 'life', 'like',\n",
       "       'likely', 'limited', 'live', 'living', 'local', 'long', 'look',\n",
       "       'loss', 'low', 'lower', 'made', 'main', 'maintain', 'major',\n",
       "       'make', 'making', 'man', 'management', 'many', 'market',\n",
       "       'material', 'matter', 'may', 'mean', 'meaning', 'measure',\n",
       "       'medical', 'medicine', 'medium', 'meet', 'member', 'mental',\n",
       "       'mentioned', 'method', 'might', 'million', 'model', 'modern',\n",
       "       'money', 'moreover', 'movement', 'much', 'multiple', 'must',\n",
       "       'national', 'natural', 'nature', 'necessary', 'need', 'needed',\n",
       "       'negative', 'never', 'new', 'next', 'non', 'note', 'number',\n",
       "       'numerous', 'objective', 'offer', 'often', 'one', 'open',\n",
       "       'operation', 'opinion', 'opportunity', 'order', 'organization',\n",
       "       'others', 'outcome', 'overall', 'pandemic', 'paper', 'part',\n",
       "       'particular', 'particularly', 'past', 'patient', 'pay', 'people',\n",
       "       'perception', 'performance', 'period', 'person', 'personal',\n",
       "       'perspective', 'physical', 'place', 'plan', 'play', 'point',\n",
       "       'policy', 'political', 'population', 'position', 'positive',\n",
       "       'possibility', 'possible', 'potential', 'power', 'pp', 'practice',\n",
       "       'present', 'presented', 'press', 'prevent', 'primary', 'principle',\n",
       "       'problem', 'process', 'product', 'production', 'professional',\n",
       "       'program', 'project', 'promote', 'proper', 'provide', 'provided',\n",
       "       'provides', 'providing', 'public', 'purpose', 'put', 'quality',\n",
       "       'question', 'range', 'rate', 'rather', 'real', 'reason', 'receive',\n",
       "       'reduce', 'reference', 'regarding', 'related', 'relation',\n",
       "       'relationship', 'relevant', 'report', 'require', 'required',\n",
       "       'requires', 'research', 'researcher', 'resource', 'response',\n",
       "       'responsibility', 'responsible', 'result', 'review', 'right',\n",
       "       'risk', 'role', 'rule', 'safety', 'say', 'science', 'second',\n",
       "       'security', 'see', 'seen', 'self', 'service', 'set', 'setting',\n",
       "       'several', 'severe', 'share', 'show', 'side', 'significant',\n",
       "       'significantly', 'similar', 'since', 'situation', 'skill', 'small',\n",
       "       'social', 'society', 'solution', 'source', 'specific', 'spread',\n",
       "       'stage', 'standard', 'start', 'state', 'statement', 'status',\n",
       "       'step', 'still', 'story', 'strategy', 'strong', 'structure',\n",
       "       'study', 'subject', 'success', 'successful', 'support', 'system',\n",
       "       'table', 'take', 'taken', 'taking', 'task', 'technology', 'term',\n",
       "       'theory', 'therefore', 'thing', 'think', 'third', 'though',\n",
       "       'thought', 'threat', 'three', 'throughout', 'thus', 'time',\n",
       "       'today', 'together', 'tool', 'topic', 'towards', 'treatment',\n",
       "       'trend', 'turn', 'two', 'type', 'understand', 'understanding',\n",
       "       'unique', 'united', 'university', 'us', 'use', 'used', 'using',\n",
       "       'usually', 'value', 'various', 'view', 'vital', 'want', 'way',\n",
       "       'web', 'well', 'whether', 'white', 'whole', 'within', 'without',\n",
       "       'woman', 'word', 'work', 'worker', 'working', 'world', 'would',\n",
       "       'writing', 'year', 'young'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec3.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "368a78d5-0e20-4500-8d23-7bac8accebf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['al 2020', 'content introduction', 'covid 19', 'essay table',\n",
       "       'essay table content', 'et al', 'et al 2020', 'research paper',\n",
       "       'table content', 'table content introduction', 'united state',\n",
       "       'work cited'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec4 = CountVectorizer(preprocessor=preprocess_text2,max_df=0.9,min_df=0.1, ngram_range=(2,3))\n",
    "X4 = vec4.fit_transform(df.text[:1000])\n",
    "vec4.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ad9fab-ff72-4a2f-a7f8-e44bf51f062e",
   "metadata": {},
   "source": [
    "## Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b505b72-5113-4ebc-945d-17283978efdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "76b00d20-428b-47a5-8b29-82a20c4d17c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc2vec(data):\n",
    "    '''\n",
    "    https://www.geeksforgeeks.org/doc2vec-in-nlp/\n",
    "    '''\n",
    "    \n",
    "    tagged_data = [TaggedDocument(words=word_tokenize(doc.lower()),\n",
    "                              tags=[str(i)]) for i,doc in enumerate(data)]\n",
    "    # train the Doc2vec model\n",
    "    model = Doc2Vec(vector_size=20,\n",
    "                    min_count=2, epochs=50)\n",
    "    model.build_vocab(tagged_data)\n",
    "    model.train(tagged_data,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.epochs)\n",
    "     \n",
    "    # get the document vectors\n",
    "    document_vectors = [model.infer_vector(\n",
    "        word_tokenize(doc.lower())) for doc in data]\n",
    "\n",
    "    return document_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8dc50736-666f-46f5-b7f1-8e4a03410827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent ai: 35.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\color\\AppData\\Local\\Temp\\ipykernel_29864\\875810769.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  data = df.groupby('source', group_keys=False).apply(lambda x: x.sample(frac=0.001, random_state=0))\n"
     ]
    }
   ],
   "source": [
    "# Reporting the proportion of samples that are ai generated\n",
    "print('Percent ai:', round(df[df['source'] == 'ai'].shape[0]/df[df['source'] == 'human'].shape[0]*100, 3))\n",
    "\n",
    "# Taking a stratified sample of 0.1% of the data\n",
    "# maintaining same proportions of human and ai samples\n",
    "data = df.groupby('source', group_keys=False).apply(lambda x: x.sample(frac=0.001, random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5fc519d0-83b4-4b6c-a788-9793cc000530",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29864\\1065450164.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpreprocess_text2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29864\\1610716031.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpreprocess_text2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# encoding to ascii\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ascii'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ascii'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# convert text to lower case\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pr_project\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6296\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6297\u001b[0m         ):\n\u001b[0;32m   6298\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "preprocess_text2(data.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e507a067-ff5d-4bc5-a7ca-ec9cba3b056f",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f0283ac6-64de-4bee-9cc7-af620dccb44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5b0ab80d-c08f-492f-bf2a-751acb2454ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CI(metric, confidence):\n",
    "    a,b = stats.t.interval(confidence, \n",
    "                         len(metric)-1, \n",
    "                         loc=metric.mean(), \n",
    "                         scale=metric.std(ddof=1)/np.sqrt(len(metric)))\n",
    "    return a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0c739f1d-53ae-4c46-b02b-db9d32b0ab08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(X_train, X_test, t_train, t_test, model, confidence=0.95, scoring='accuracy'):\n",
    "\n",
    "    y_train = gnb.predict(X_train)\n",
    "    y_test = gnb.predict(X_test)\n",
    "    \n",
    "    scores = cross_val_score(model,\n",
    "                             X_train, \n",
    "                             t_train, \n",
    "                             scoring=scoring, \n",
    "                             cv=KFold(10, shuffle=True, random_state=0))\n",
    "    \n",
    "    a,b = CI(scores, confidence)\n",
    "    \n",
    "    print('===================Naive Bayes Performance=====================')\n",
    "    print('95% CI = [', a, b, ']')\n",
    "    print('Train: ', classification_report(t_train, y_train))\n",
    "    print('Test: ', classification_report(t_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "94ce20a6-2d3b-49b8-8912-7c7f1702beb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GaussianNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.GaussianNB.html\">?<span>Documentation for GaussianNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GaussianNB()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorize the documents (using non-preprocessed data)\n",
    "v = doc2vec(data['text'])\n",
    "\n",
    "# Set up the data and labels\n",
    "X = np.array(v)\n",
    "t = data.source\n",
    "d = {'human' : 0, 'ai' : 1}\n",
    "t = t.map(d, na_action='ignore')\n",
    "X_train, X_test, t_train, t_test = train_test_split(X, t, test_size=0.2, random_state=0)\n",
    "\n",
    "# Naive Bayes Classifier\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a25bed55-0179-4235-8a8d-ae7b932c398e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================Naive Bayes Performance=====================\n",
      "95% CI = [ 0.7357685953367065 0.7844534123853012 ]\n",
      "Train:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85       827\n",
      "           1       0.56      0.49      0.52       286\n",
      "\n",
      "    accuracy                           0.77      1113\n",
      "   macro avg       0.69      0.68      0.68      1113\n",
      "weighted avg       0.76      0.77      0.76      1113\n",
      "\n",
      "Test:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       201\n",
      "           1       0.56      0.45      0.50        78\n",
      "\n",
      "    accuracy                           0.75       279\n",
      "   macro avg       0.68      0.65      0.66       279\n",
      "weighted avg       0.73      0.75      0.74       279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation(X_train, X_test, t_train, t_test, gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a2b3f6-c4c9-429d-be65-869f3f8011d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
